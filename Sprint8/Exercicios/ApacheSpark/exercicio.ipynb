{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicio Apache Spark\n",
    "\n",
    "### Etapa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|             _c0|\n",
      "+----------------+\n",
      "|  Frances Bennet|\n",
      "|   Jamie Russell|\n",
      "|  Edward Kistler|\n",
      "|   Sheila Maurer|\n",
      "|Donald Golightly|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Cria a Spark Session\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Exercicio Intro\").getOrCreate()\n",
    "\n",
    "# Nome do arquivo csv\n",
    "csv = \"nomes_aleatorios.txt\"\n",
    "\n",
    "# Lê o arquivo CSV e cria o DataFrame\n",
    "df_nomes = spark.read.csv(csv, header=False, inferSchema=True)\n",
    "\n",
    "# Mostra as primeiras 5 linhas do DataFrame\n",
    "df_nomes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Nomes: string (nullable = true)\n",
      "\n",
      "+-----------------+\n",
      "|            Nomes|\n",
      "+-----------------+\n",
      "|   Frances Bennet|\n",
      "|    Jamie Russell|\n",
      "|   Edward Kistler|\n",
      "|    Sheila Maurer|\n",
      "| Donald Golightly|\n",
      "|       David Gray|\n",
      "|      Joy Bennett|\n",
      "|      Paul Kriese|\n",
      "|Berniece Ornellas|\n",
      "|    Brian Farrell|\n",
      "+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renomeia a coluna para 'Nomes'\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
    "\n",
    "# Imprime o esquema do DataFrame\n",
    "df_nomes.printSchema()\n",
    "\n",
    "# Mostra 10 linhas do DataFrame\n",
    "df_nomes.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|            Nomes|Escolaridade|\n",
      "+-----------------+------------+\n",
      "|   Frances Bennet| Fundamental|\n",
      "|    Jamie Russell|    Superior|\n",
      "|   Edward Kistler| Fundamental|\n",
      "|    Sheila Maurer|       Medio|\n",
      "| Donald Golightly|    Superior|\n",
      "|       David Gray| Fundamental|\n",
      "|      Joy Bennett|       Medio|\n",
      "|      Paul Kriese|       Medio|\n",
      "|Berniece Ornellas|    Superior|\n",
      "|    Brian Farrell|       Medio|\n",
      "+-----------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, when, rand\n",
    "\n",
    "# Adiciona a coluna 'Escolaridade' com valores aleatórios\n",
    "df_nomes = df_nomes.withColumn(\n",
    "    \"Escolaridade\",\n",
    "    when(rand() < 0.33, lit(\"Fundamental\"))\n",
    "    .when((rand() >= 0.33) & (rand() < 0.66), lit(\"Medio\"))\n",
    "    .otherwise(lit(\"Superior\"))\n",
    ")\n",
    "\n",
    "df_nomes.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+---------+\n",
      "|            Nomes|Escolaridade|     Pais|\n",
      "+-----------------+------------+---------+\n",
      "|   Frances Bennet| Fundamental|    Chile|\n",
      "|    Jamie Russell|    Superior|   Brasil|\n",
      "|   Edward Kistler| Fundamental|Argentina|\n",
      "|    Sheila Maurer|       Medio| Suriname|\n",
      "| Donald Golightly|    Superior|  Bolívia|\n",
      "|       David Gray| Fundamental| Colômbia|\n",
      "|      Joy Bennett|       Medio| Suriname|\n",
      "|      Paul Kriese|       Medio|    Chile|\n",
      "|Berniece Ornellas|    Superior| Colômbia|\n",
      "|    Brian Farrell|       Medio|    Chile|\n",
      "+-----------------+------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, rand\n",
    "\n",
    "# Lista de países da América do Sul\n",
    "paises = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\", \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
    "\n",
    "# Adiciona a coluna 'Pais' com valores aleatórios\n",
    "df_nomes = df_nomes.withColumn(\n",
    "    \"Pais\",\n",
    "    when(rand() < 1/13, lit(\"Argentina\"))\n",
    "    .when((rand() >= 1/13) & (rand() < 2/13), lit(\"Bolívia\"))\n",
    "    .when((rand() >= 2/13) & (rand() < 3/13), lit(\"Brasil\"))\n",
    "    .when((rand() >= 3/13) & (rand() < 4/13), lit(\"Chile\"))\n",
    "    .when((rand() >= 4/13) & (rand() < 5/13), lit(\"Colômbia\"))\n",
    "    .when((rand() >= 5/13) & (rand() < 6/13), lit(\"Equador\"))\n",
    "    .when((rand() >= 6/13) & (rand() < 7/13), lit(\"Guiana\"))\n",
    "    .when((rand() >= 7/13) & (rand() < 8/13), lit(\"Paraguai\"))\n",
    "    .when((rand() >= 8/13) & (rand() < 9/13), lit(\"Peru\"))\n",
    "    .when((rand() >= 9/13) & (rand() < 10/13), lit(\"Suriname\"))\n",
    "    .when((rand() >= 10/13) & (rand() < 11/13), lit(\"Uruguai\"))\n",
    "    .when((rand() >= 11/13) & (rand() < 12/13), lit(\"Venezuela\"))\n",
    "    .otherwise(lit(\"Guiana Francesa\"))\n",
    ")\n",
    "\n",
    "df_nomes.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+---------+-------------+\n",
      "|            Nomes|Escolaridade|     Pais|AnoNascimento|\n",
      "+-----------------+------------+---------+-------------+\n",
      "|   Frances Bennet| Fundamental|    Chile|         1945|\n",
      "|    Jamie Russell|    Superior|   Brasil|         2004|\n",
      "|   Edward Kistler| Fundamental|Argentina|         1974|\n",
      "|    Sheila Maurer|       Medio| Suriname|         1994|\n",
      "| Donald Golightly|    Superior|  Bolívia|         2009|\n",
      "|       David Gray| Fundamental| Colômbia|         1969|\n",
      "|      Joy Bennett|       Medio| Suriname|         2003|\n",
      "|      Paul Kriese|       Medio|    Chile|         1967|\n",
      "|Berniece Ornellas|    Superior| Colômbia|         1974|\n",
      "|    Brian Farrell|       Medio|    Chile|         1955|\n",
      "+-----------------+------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, when, rand\n",
    "\n",
    "# Adiciona a coluna 'AnoNascimento' com valores aleatórios entre 1945 e 2010\n",
    "df_nomes = df_nomes.withColumn(\n",
    "    \"AnoNascimento\",\n",
    "    (lit(1945) + (rand() * (lit(2010) - lit(1945)))).cast(\"integer\")\n",
    ")\n",
    "\n",
    "df_nomes.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------+-------------+\n",
      "|           Nomes|Escolaridade|    Pais|AnoNascimento|\n",
      "+----------------+------------+--------+-------------+\n",
      "|   Jamie Russell|    Superior|  Brasil|         2004|\n",
      "|Donald Golightly|    Superior| Bolívia|         2009|\n",
      "|     Joy Bennett|       Medio|Suriname|         2003|\n",
      "|   Tracy Herring|    Superior|  Brasil|         2002|\n",
      "|    Ernest Hulet|    Superior|Paraguai|         2003|\n",
      "|    David Medina|       Medio|  Brasil|         2006|\n",
      "|    Roxie Bernal| Fundamental|Suriname|         2002|\n",
      "| Jerry Chynoweth|    Superior|  Brasil|         2007|\n",
      "|     Milton Rowe|    Superior|Paraguai|         2000|\n",
      "|    Juliet Liles|    Superior|  Brasil|         2006|\n",
      "+----------------+------------+--------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seleciona pessoas que nasceram neste século (>= 2000)\n",
    "df_select = df_nomes.filter(df_nomes.AnoNascimento >= 2000)\n",
    "\n",
    "# Mostra 10 linhas do DataFrame resultante\n",
    "df_select.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------+-------------+\n",
      "|           Nomes|Escolaridade|    Pais|AnoNascimento|\n",
      "+----------------+------------+--------+-------------+\n",
      "|   Jamie Russell|    Superior|  Brasil|         2004|\n",
      "|Donald Golightly|    Superior| Bolívia|         2009|\n",
      "|     Joy Bennett|       Medio|Suriname|         2003|\n",
      "|   Tracy Herring|    Superior|  Brasil|         2002|\n",
      "|    Ernest Hulet|    Superior|Paraguai|         2003|\n",
      "|    David Medina|       Medio|  Brasil|         2006|\n",
      "|    Roxie Bernal| Fundamental|Suriname|         2002|\n",
      "| Jerry Chynoweth|    Superior|  Brasil|         2007|\n",
      "|     Milton Rowe|    Superior|Paraguai|         2000|\n",
      "|    Juliet Liles|    Superior|  Brasil|         2006|\n",
      "+----------------+------------+--------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria uma tabela temporária\n",
    "df_nomes.createOrReplaceTempView(\"pessoas\")\n",
    "\n",
    "# Executa o comando SQL para selecionar pessoas que nasceram neste século\n",
    "df_select_sql = spark.sql(\"SELECT * FROM pessoas WHERE AnoNascimento >= 2000\")\n",
    "\n",
    "# Mostra 10 linhas do DataFrame resultante\n",
    "df_select_sql.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Millennials: 2307870\n"
     ]
    }
   ],
   "source": [
    "# Conta o número de pessoas da geração Millennials\n",
    "df_millennials = df_nomes.filter((df_nomes.AnoNascimento >= 1980) & (df_nomes.AnoNascimento <= 1994))\n",
    "df_millennials_count = df_millennials.count()\n",
    "\n",
    "print(f\"Numero de Millennials: {df_millennials_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|num_millenials|\n",
      "+--------------+\n",
      "|       2307870|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa o comando SQL para contar pessoas da geração Millennials\n",
    "df_millennials_sql = spark.sql(\"\"\"SELECT COUNT(*) as num_millenials \n",
    "                               FROM pessoas  \n",
    "                               WHERE AnoNascimento BETWEEN 1980 AND 1994\"\"\")\n",
    "df_millennials_sql.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Etapa 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+----------+\n",
      "|Pais           |Geracao     |Quantidade|\n",
      "+---------------+------------+----------+\n",
      "|Argentina      |Baby Boomers|236842    |\n",
      "|Argentina      |Geracao X   |177560    |\n",
      "|Argentina      |Geracao Z   |177513    |\n",
      "|Argentina      |Millennials |177268    |\n",
      "|Bolívia        |Baby Boomers|403099    |\n",
      "|Bolívia        |Geracao X   |301942    |\n",
      "|Bolívia        |Geracao Z   |303626    |\n",
      "|Bolívia        |Millennials |302806    |\n",
      "|Brasil         |Baby Boomers|475907    |\n",
      "|Brasil         |Geracao X   |356743    |\n",
      "|Brasil         |Geracao Z   |357429    |\n",
      "|Brasil         |Millennials |357692    |\n",
      "|Chile          |Baby Boomers|464482    |\n",
      "|Chile          |Geracao X   |347904    |\n",
      "|Chile          |Geracao Z   |346914    |\n",
      "|Chile          |Millennials |347257    |\n",
      "|Colômbia       |Baby Boomers|398563    |\n",
      "|Colômbia       |Geracao X   |299765    |\n",
      "|Colômbia       |Geracao Z   |298964    |\n",
      "|Colômbia       |Millennials |298614    |\n",
      "|Equador        |Baby Boomers|312159    |\n",
      "|Equador        |Geracao X   |233677    |\n",
      "|Equador        |Geracao Z   |234007    |\n",
      "|Equador        |Millennials |233986    |\n",
      "|Guiana         |Baby Boomers|227141    |\n",
      "|Guiana         |Geracao X   |171273    |\n",
      "|Guiana         |Geracao Z   |170353    |\n",
      "|Guiana         |Millennials |171062    |\n",
      "|Guiana Francesa|Baby Boomers|154370    |\n",
      "|Guiana Francesa|Geracao X   |115665    |\n",
      "|Guiana Francesa|Geracao Z   |116431    |\n",
      "|Guiana Francesa|Millennials |116317    |\n",
      "|Paraguai       |Baby Boomers|158978    |\n",
      "|Paraguai       |Geracao X   |119210    |\n",
      "|Paraguai       |Geracao Z   |118889    |\n",
      "|Paraguai       |Millennials |119234    |\n",
      "|Peru           |Baby Boomers|105986    |\n",
      "|Peru           |Geracao X   |80075     |\n",
      "|Peru           |Geracao Z   |79751     |\n",
      "|Peru           |Millennials |79764     |\n",
      "|Suriname       |Baby Boomers|69083     |\n",
      "|Suriname       |Geracao X   |52382     |\n",
      "|Suriname       |Geracao Z   |52006     |\n",
      "|Suriname       |Millennials |52097     |\n",
      "|Uruguai        |Baby Boomers|43693     |\n",
      "|Uruguai        |Geracao X   |33042     |\n",
      "|Uruguai        |Geracao Z   |32846     |\n",
      "|Uruguai        |Millennials |32712     |\n",
      "|Venezuela      |Baby Boomers|25562     |\n",
      "|Venezuela      |Geracao X   |19168     |\n",
      "|Venezuela      |Geracao Z   |19130     |\n",
      "|Venezuela      |Millennials |19061     |\n",
      "+---------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "# Define as gerações\n",
    "geracoes = [\n",
    "    (\"Baby Boomers\", 1944, 1964),\n",
    "    (\"Geracao X\", 1965, 1979),\n",
    "    (\"Millennials\", 1980, 1994),\n",
    "    (\"Geracao Z\", 1995, 2015)\n",
    "]\n",
    "\n",
    "# Inicia a coluna 'Geracao' com valores nulos\n",
    "df_nomes = df_nomes.withColumn(\"Geracao\", lit(None))\n",
    "\n",
    "# Atualiza a coluna 'Geracao' com base nos intervalos de anos\n",
    "for nome, inicio, fim in geracoes:\n",
    "    df_nomes = df_nomes.withColumn(\"Geracao\", when((df_nomes.AnoNascimento >= inicio) & (df_nomes.AnoNascimento <= fim), lit(nome)).otherwise(df_nomes.Geracao))\n",
    "\n",
    "# Cria uma tabela temporária com a nova coluna 'Geracao'\n",
    "df_nomes.createOrReplaceTempView(\"pessoas_geracoes\")\n",
    "\n",
    "# Executa o comando SQL para obter a quantidade de pessoas por país e geração\n",
    "df_pessoas_pais_geracao = spark.sql(\"\"\"\n",
    "    SELECT Pais, Geracao, COUNT(*) AS Quantidade\n",
    "    FROM pessoas_geracoes\n",
    "    GROUP BY Pais, Geracao\n",
    "    ORDER BY Pais, Geracao\n",
    "\"\"\")\n",
    "\n",
    "# Mostra todas as linhas do DataFrame resultante\n",
    "total_linhas = df_pessoas_pais_geracao.count()\n",
    "df_pessoas_pais_geracao.show(total_linhas, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
